{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10764223,"sourceType":"datasetVersion","datasetId":6677100}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from cloudpickle import load\nfrom tensorflow.keras.models import model_from_json \nimport pandas as pd\nimport tensorflow as tf\n\nvalues = [['192.168.60.100', 65, '192.168.40.2',   357,   6, 10, 0, 10, 0, 0, 15360], \n          ['192.168.60.100', 65, '192.168.40.2',   357,   6, 10, 0, 10, 0, 0, 15360],\n          ['192.168.50.2'  , 65, '192.168.40.2',   357,   6, 10, 0, 10, 0, 0, 15360],\n          ['192.168.50.100', 65, '192.168.60.100', 357,   6, 10, 0, 10, 0, 0, 15360]]\n\ncolumns = ['IPV4_SRC_ADDR', 'L4_SRC_PORT', 'IPV4_DST_ADDR', 'L4_DST_PORT',\\\n    'PROTOCOL', 'IN_BYTES', 'OUT_BYTES', 'IN_PKTS', 'OUT_PKTS', 'TCP_FLAGS','FLOW_DURATION_MILLISECONDS']\ndf = pd.DataFrame(values, columns=columns)\n#print(df)\n\n\ndef  predict_packets(df):\n    result = ['is an anomaly', 'is a normal activity']\n    #Import process\n    process = load(open('/kaggle/input/detection-anomaly-model/processing.pkl','rb'))\n \n    #Import model \n    #from tensorflow.keras.models  import model_from_json\n\n    # load json and create model\n    json_file = open('/kaggle/input/detection-anomaly-model/model.json', 'r')\n    loaded_model_json = json_file.read()\n    json_file.close()\n    model = model_from_json(loaded_model_json)\n\n    # load weights into new model\n    model.load_weights('/kaggle/input/detection-anomaly-model/model.weights.h5')\n    print(\"Loaded model from disk\") \n\n    columns = ['IPV4_SRC_ADDR', 'L4_SRC_PORT', 'IPV4_DST_ADDR', 'L4_DST_PORT',\\\n    'PROTOCOL', 'IN_BYTES', 'OUT_BYTES', 'IN_PKTS',  'OUT_PKTS', 'TCP_FLAGS','FLOW_DURATION_MILLISECONDS']\n    df = pd.DataFrame(values, columns=columns)\n    df_result =  pd.DataFrame(values, columns=columns) \n    \n    \n    #Adress source\n    df[['IPV4_SRC_ADDR_network1','IPV4_SRC_ADDR_network2','IPV4_SRC_ADDR_hote1',\\\n    'IPV4_SRC_ADDR_hote2']]=df['IPV4_SRC_ADDR'].str.split('.', expand=True)\n    df = process['target_encoding_src_network1'].merge(df, on='IPV4_SRC_ADDR_network1')\n    df = process['target_encoding_src_network2'].merge(df, on='IPV4_SRC_ADDR_network2')\n    df = process['target_encoding_src_hote1'].merge(df, on='IPV4_SRC_ADDR_hote1')\n    df = process['target_encoding_src_hote2'].merge(df, on='IPV4_SRC_ADDR_hote2')\n\n    #Destinaton adress\n    df[['IPV4_DST_ADDR_network1','IPV4_DST_ADDR_network2','IPV4_DST_ADDR_hote1',\\\n    'IPV4_DST_ADDR_hote2']]= df['IPV4_DST_ADDR'].str.split('.', expand=True)\n    df = process['target_encoding_dst_network1'].merge(df, on='IPV4_DST_ADDR_network1')\n    df = process['target_encoding_dst_network2'].merge(df, on='IPV4_DST_ADDR_network2')\n    df = process['target_encoding_dst_hote1'].merge(df, on='IPV4_DST_ADDR_hote1')\n    df = process['target_encoding_dst_hote2'].merge(df, on='IPV4_DST_ADDR_hote2')\n\n    #Deal with src port address\n    df = process['target_encoding_l4_src_port'].merge(df, on='L4_SRC_PORT')\n\n    #Deal with dst port address\n    df = process['target_encoding_l4_dst_port'].merge(df, on='L4_DST_PORT')\n\n    #Deal with protocol\n    df= process['target_encoding_protocol'].merge(df, on='PROTOCOL')\n    #Deal with tcp_flags\n    df= process['target_encoding_tcp_flags'].merge(df, on='TCP_FLAGS')\n    \n    #Drop col\n    drop_col = ['IPV4_SRC_ADDR', 'IPV4_DST_ADDR',  'TCP_FLAGS', 'PROTOCOL', \n    'L4_DST_PORT', 'L4_SRC_PORT', 'IPV4_DST_ADDR_hote2','IPV4_DST_ADDR_hote1','IPV4_DST_ADDR_network2',\n    'IPV4_DST_ADDR_network1', 'IPV4_SRC_ADDR_hote2','IPV4_SRC_ADDR_hote1', 'IPV4_SRC_ADDR_network2',\n    'IPV4_SRC_ADDR_network1']\n    df = df.drop(columns=drop_col)\n\n    #Standard scaler\n    df_scaled = process['stdScaler'].transform(df)\n\n    #Prediction\n    reconstruction_result = model.predict(df_scaled)\n    loss = tf.keras.losses.mae(reconstruction_result, df_scaled)\n   \n    result = ['Activité normale', 'Anomalie']\n    threshold = process['threshold']\n    outliers = loss > threshold\n    print(outliers)\n    print('\\n')\n        \n    for index, element  in enumerate(outliers):\n        a = element.numpy().any().astype(int)\n        df_result.loc[index, 'Label'] = a\n    print(df_result)\n    \n\npredict_packets(values)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T12:43:34.182201Z","iopub.execute_input":"2025-02-16T12:43:34.182835Z","iopub.status.idle":"2025-02-16T12:43:34.600013Z","shell.execute_reply.started":"2025-02-16T12:43:34.182803Z","shell.execute_reply":"2025-02-16T12:43:34.598586Z"}},"outputs":[{"name":"stdout","text":"Loaded model from disk\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\ntf.Tensor([ True  True  True  True], shape=(4,), dtype=bool)\n\n\n    IPV4_SRC_ADDR  L4_SRC_PORT   IPV4_DST_ADDR  L4_DST_PORT  PROTOCOL  \\\n0  192.168.60.100           65    192.168.40.2          357         6   \n1  192.168.60.100           65    192.168.40.2          357         6   \n2    192.168.50.2           65    192.168.40.2          357         6   \n3  192.168.50.100           65  192.168.60.100          357         6   \n\n   IN_BYTES  OUT_BYTES  IN_PKTS  OUT_PKTS  TCP_FLAGS  \\\n0        10          0       10         0          0   \n1        10          0       10         0          0   \n2        10          0       10         0          0   \n3        10          0       10         0          0   \n\n   FLOW_DURATION_MILLISECONDS  Label  \n0                       15360    1.0  \n1                       15360    1.0  \n2                       15360    1.0  \n3                       15360    1.0  \n","output_type":"stream"}],"execution_count":3}]}